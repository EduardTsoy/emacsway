
О проблемах инвалидации кэша. Тегирование кэша.
===============================================


.. post:: May 21, 2016
   :language: ru
   :tags: cache
   :category:
   :author: Ivan Zakrevsky

Здесь я расскажу о своем опыте решения проблем инвалидации кэша, и о принципах работы библиотеки `cache-tagging`_.

.. contents:: Содержание


Проблема зависимостей в кэшировании
===================================

При редактировании данных, необходимо удалить так же и все кэши, содержащие данные этой модели.
Например, при редактировании продукта, который присутствует на закэшированной главной странице компании, требуется инвалидировать и ее кэш тоже.
Другой случай, - обновляя данные пользователя (например, фамилию), мы должны так же удалить все кэши страниц его постов, на которых присутствуют обновленные данные.

Обычно за инвалидацию кэша отвечает паттерн `Observer`_, или его разновидность - паттерн Multicast.
А это значит, что обработчик события должен быть осведомлен обо всех зависимых компонетах системы, что нарушает принцип инкапсуляции.

И тут на выручку приходит тегирование кэша, т.е. прошивание кэша метками.
Например, главная страница может быть прошита тэгом ``product.id:635``.
А все посты пользователя могут быть прошиты меткой ``user.id:10``.
Коллекции можно кэшировать составным тэгом, состоящим из критериев выборки, например ``type.id:1;category.id:15;region.id:239``.

Теперь достаточно инвалидировать метку, чтобы все зависимые кэши автоматически инвалидировались.
Эта технология не нова, и активно используется в других языках программирования.
Одно время ее даже пытались внедрить в memcached, см. `memcached-tag <http://code.google.com/p/memcached-tag/>`_.


Накладные расходы при чтении кэша или его создании?
===================================================

Возникает вопрос реализации инвалидации зависимых от метки кэшей.
Возможны два варианта:

\1. При инвалидации метки физически уничтожать все зависимые кэши.
Для реализации такого подхода потребуются накладные расходы при создании кэша, чтобы добавить информацию о нем в список (точнее, множество) зависимостей каждой метки (например, используя `SADD <http://redis.io/commands/sadd>`_).
Недостаток заключается в том, что инвалидация большого количества зависимых кэшей требует определенного времени.

\2. При инвалидации метки просто изменять версию этой метки.
Для реализации потребуется добавлять в кэш информацию о версиях меток.
При чтении кэша потребуются накладные расходы для сверки версии каждой его метки, и, если версия устарела, то кэш считается недействительным.
Достоинство этого подхода заключается в мгновенной инвалидации метки и всех ее зависимых кэшей.

Я выбрал второй вариант.


Многоуровневое кэширование и тегирование
========================================

Поскольку метки сверяются в момент чтения кэша, давайте представим, что произойдет, если один кэш поглощается другим кэшем.
Многоуровневый кэш - не редкость.
В таком случае, метки низлежащего, дочернего кэша никогда не пройдут сверку, и родительский кэш останется с неактуальными данными.
Необходимо явно передать метки родительскому кэшу в момент его создания, что может нарушать принцип инкапсуляции.

Поэтому система кэширования должна автоматически отслеживать связи между вложенными кэшами, и передавать метки от дочернего кэша к родительскому.


Проблема репликации
===================

При инвалидации кэша параллельный поток может успеть воссоздать кэш с устаревшими данными, прочитанными из slave в перид времени после инвалидации кэша, но до момента обновления slave.

Лучшим решением было бы блокирование создания кэша до момента обновления slave.
Но, во-первых, это сопряжено с определенными накладными расходами, а во-вторых, все потоки (в том числе и текущий) продолжают считывать устаревшие данные из slave (если не указано явное чтение из мастера).
Поэтому, компромиссным решением может быть просто повторная инвалидация кэша через период времени гарантированного обновления slave.

В своей практике мне приходилось встречать использование регенерации кэша вместо его удаления/инвалидации.
Такой подход влечет за собой не совсем эффективное использование памяти кэша (работающего по LRU-принципу).
К тому же, он не решает проблему сложности инвалидации и по сути мало чем отличается от обычного удаления кэша, возлагая всю сложность на само приложение.
Так же он таит множество потенциальных баг.
Например, он чувствителен к качеству ORM, и если ORM не приводит все атрибуты инстанции модели к нужному типу при сохранении, то в кэш записываются неверные типы данных.
Мне приходилось видеть случай, когда атрибут даты записывался к кэш в формате строки, в таком же виде, в каком он пришел от клиента.
Хотя он и записывался в БД корректно, но модель не делала приведение типов без дополнительных манипуляций при сохранении.


Проблема транзакций
===================

Если Ваш проект имеет более-менее нормальную посещаемость, то с момента инвалидации кэша и до момента фиксации транзакции, параллельный поток может успеть воссоздать кэш с устаревшими данными.
В отличии от проблемы репликации, здесь проявление проблемы сильно зависит от качества ОРМ, и вероятность проблемы снижается при использовании паттерна `Unit of Work`_.

Рассмотрим проблему для каждого `уровня изоляции транзакции <Isolation_>`_ по отдельности.


Read uncommitted
----------------

Тут все просто, и никакой проблемы не может быть в принципе. В случае использования репликации достаточно сделать отложенный повтор инвалидации через интервал времени гарантированного обновления slave.


Read committed
--------------

Тут уже проблема может присутствовать, особенно если Вы используете `ActiveRecord`_.
Использование паттерна `DataMapper`_ в сочетании с `Unit of Work`_ заметно снижает интервал времени между сохранением данных и фиксацией транзакции, но вероятность проблемы все равно остается.

В отличии от проблемы репликации, здесь предпочтительней было бы блокирование создания кэша до момента фиксации транзакции, так как текущий поток видит в БД не те данные, которые видят параллельные потоки.
А поскольку нельзя гарантированно сказать какой именно поток, текущий или параллельный, создаст новый кэш, то создание кэша до фиксации транзакции было бы желательно избежать.

Тем не менее, этот уровень изоляции не является достаточно серьезным, и выбирается, как правило, для повышения степени параллелизма, т.е. с той же целью что и репликация.
А в таком случае, эта проблема обычно поглощается проблемой репликации, ведь чтение делается все равно из slave.

Поэтому, дорогостоящая блокировка может быть заменена просто повторной инвалидацией после фиксации транзакции.


Repeatable reads
----------------

Этот случай наиболее интересен.
Здесь уже без блокировки создания кэша не обойтись, хотя бы потому, что нам нужно знать не только список меток, но и время инвалидации каждой метки.

Мало того, что мы должны заблокировать метку с момента инвалидации до момента фиксации транзакции, так мы еще и не можем создавать кэш в тех параллельных транзакциях, которые были открыты до момента инвалидации любой из меткок кэша.

Хорошая новость заключается в том, что раз уж мы и вынуждены мириться с накладными расходами на блокировку меток, то можно блокировать их вплоть до обновления slave.


Serializable
------------

Поскольку несуществующие объекты обычно не кэшируются, то здесь достаточно ограничится той же проблематикой, что и для уровня `Repeatable reads`_.


Динамические окна в кэше
========================

Есть два взаимно-дополняющих паттерна, основанных на диаметрально противоположных принципах, - `Decorator`_ и `Strategy`_.
В первом случае изменяемая логика располагается вокруг объявленного кода, во втором - передается внутрь него.
Обычное кэширование имеет черты паттерна `Decorator`_, когда динамический код расположен вокруг закэшированной логики.
Но иногда в кэше небольшой фрагмент логики не должен подлежать кэшированию.
Например, персонализированные данные пользователя, проверка прав и т.п.

Один из вариантов решения этой проблемы - это использование технологии `Server Side Includes <https://en.wikipedia.org/wiki/Server_Side_Includes>`_.

Другой вариант - это использование двухфазной шаблонизации, например, используя библиотеку `django-phased <https://pypi.python.org/pypi/django-phased>`_.
Справедливости ради нужно отметить, что решение имеет немаленькое ресурсопотребление, и в некоторых случаях может нивелировать (если даже не усугублять) эффект от кэширования.
Возможно, именно поэтому, оно не получило широкого распространения.

Популярный шаблонный движок Smarty имеет функцию `{nocache} <http://www.smarty.net/docs/en/language.function.nocache.tpl>`_.

Более интересной мне показалась возможность использовать в качестве динамического окна обычный Python-код, и абстрагироваться от сторонних технологий.


Заключение
==========

Надо признать, что я уделяю этой библиотеке мало внимания (а писалась она еще на заре моего освоения языка Python), и многое из того, что хотелось бы сделать, там не сделано.

.. _cache-tagging: https://bitbucket.org/emacsway/cache-tagging

.. _Decorator: https://en.wikipedia.org/wiki/Decorator_pattern
.. _Strategy: https://en.wikipedia.org/wiki/Strategy_pattern
.. _Isolation: https://en.wikipedia.org/wiki/Isolation_(database_systems)
.. _Observer: https://en.wikipedia.org/wiki/Observer_pattern

.. _ActiveRecord: http://www.martinfowler.com/eaaCatalog/activeRecord.html
.. _DataMapper: http://martinfowler.com/eaaCatalog/dataMapper.html
.. _Unit of Work: http://martinfowler.com/eaaCatalog/unitOfWork.html
